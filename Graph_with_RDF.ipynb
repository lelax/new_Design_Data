{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "396aa051",
   "metadata": {},
   "source": [
    "## RDF triplestore graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a12ed17b",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 321)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m321\u001b[0m\n\u001b[0;31m    else:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from rdflib import Graph\n",
    "\n",
    "my_graph = Graph()\n",
    "\n",
    "from rdflib import URIRef\n",
    "\n",
    "# classes of resources \n",
    "JournalArticle = URIRef(\"https://schema.org/ScholarlyArticle\")\n",
    "BookChapter = URIRef(\"https://schema.org/Chapter\")\n",
    "ProceedingsPaper = URIRef(\"http://purl.org/spar/fabio/ProceedingsPaper\")\n",
    "Journal = URIRef(\"https://schema.org/Periodical\")\n",
    "Book = URIRef(\"https://schema.org/Book\")\n",
    "Proceedings = URIRef(\"http://purl.org/spar/fabio/AcademicProceedings\")\n",
    "Organization = URIRef(\"https://schema.org/Organization\")\n",
    "IdentifiableEntity = URIRef(\"https://schema.org/identifier\")\n",
    "Publication = URIRef(\"https://schema.org/publication\")\n",
    "Venue = URIRef(\"https://schema.org/VenueMap\")\n",
    "Person = URIRef(\"https://schema.org/Person\")\n",
    "\n",
    "# attributes related to classes\n",
    "publicationYear = URIRef(\"https://schema.org/datePublished\")\n",
    "title = URIRef(\"http://purl.org/dc/terms/title\")\n",
    "issue = URIRef(\"https://schema.org/issueNumber\")\n",
    "volume = URIRef(\"https://schema.org/volumeNumber\")\n",
    "doi = URIRef(\"https://schema.org/identifier\")\n",
    "identifier = URIRef(\"https://schema.org/identifier\")\n",
    "name = URIRef(\"https://schema.org/name\")\n",
    "event = URIRef(\"https://schema.org/Event\")\n",
    "chapterNumber = URIRef(\"https://github.com/lelax/D_Sign_Data/blob/main/URIRef/chapterNumber\")\n",
    "givenName = URIRef(\"https://schema.org/givenName\")\n",
    "familyName = URIRef(\"https://schema.org/familyName\")\n",
    "orcid = URIRef(\"https://schema.org/orcid\")\n",
    "person = URIRef(\"https://schema.org/person\")\n",
    "venue = URIRef(\"https://schema.org/venue\")\n",
    "proceedingpapers = URIRef(\"https://schema.org/proceedingpapers\")\n",
    "doiPublisher = URIRef(\"https://schema.org/doiPublisher\")\n",
    "doiId = URIRef(\"https://schema.org/doiId\")\n",
    "\n",
    "# relations among classes\n",
    "publicationVenue = URIRef(\"https://schema.org/isPartOf\")\n",
    "publisher = URIRef(\"https://schema.org/publishedBy\")\n",
    "author = URIRef(\"http://purl.org/saws/ontology#isWrittenBy\")\n",
    "citation = URIRef(\"https://schema.org/citation\")\n",
    "\n",
    "#literal\n",
    "from rdflib import Literal\n",
    "a_string = Literal(\"a string \")\n",
    "a_number = Literal(4)\n",
    "a_boolean = Literal(True)\n",
    "\n",
    "from pandas import read_csv, Series\n",
    "from rdflib import RDF\n",
    "\n",
    "base_url = \"https://github.com/lelax/New_Design_Data/\"\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from pandas import read_json\n",
    "from pandas import read_sql\n",
    "from pandas import merge\n",
    "from pandas import concat\n",
    "from pandas import Series\n",
    "import sqlite3\n",
    "import json\n",
    "from sqlite3 import connect\n",
    "from csv import reader\n",
    "\n",
    "publications = read_csv(\"import/graph_publications.csv\", \n",
    "                        keep_default_na=False,\n",
    "                        dtype={\n",
    "                            \"id\": \"string\",\n",
    "                            \"title\": \"string\",\n",
    "                            \"type\": \"string\",\n",
    "                            \"publicationType\": \"string\",\n",
    "                            \"publication year\": \"int\",\n",
    "                            \"issue\": \"string\",\n",
    "                            \"volume\": \"string\",\n",
    "                            \"chapter\": \"string\",\n",
    "                            \"publication venue\": \"string\",\n",
    "                            \"venueType\": \"string\",\n",
    "                            \"publisher\": \"string\"        \n",
    "       \n",
    "                        })\n",
    "\n",
    "if self.path.endswith('csv'):\n",
    "                    IdentifiableEntity = read_csv(path,\n",
    "                                      keep_default_na=False,\n",
    "                                      dtype={\n",
    "                                          \"id\": \"string\",\n",
    "                                    })\n",
    "\n",
    "                    IdentifiableEntity_internal_id = {}\n",
    "                    for idx, row in IdentifiableEntity.iterrows():\n",
    "                        local_id = \"IdentifiableEntity-\" + str(idx)\n",
    "                        subj = URIRef(base_url + local_id)\n",
    "                        IdentifiableEntity_internal_id[row[\"id\"]] = subj\n",
    "                    dsd_graph.add ((subj, identifier, Literal(row[\"id\"])))\n",
    "\n",
    "                    if row[\"type\"] == \"Person\":\n",
    "                        dsd_graph.add((subj, RDF.type, person))\n",
    "                        dsd_graph.add ((subj, givenName, Literal(row[\"givenName\"])))\n",
    "                        dsd_graph.add ((subj, familyName, Literal(row[\"familyName\"])))\n",
    "                    elif row[\"type\"] == \"Publication\":\n",
    "                        dsd_graph.add((subj, RDF.type, Publication))\n",
    "                    elif row[\"type\"] == \"Venue\":\n",
    "                        dsd_graph.add((subj, RDF.type, venue))\n",
    "                    elif row[\"type\"] == \"Organization\":\n",
    "                        dsd_graph.add((subj, RDF.type, Organization))\n",
    "                        dsd_graph.add ((subj, name, Literal(row[\"name\"])))\n",
    "\n",
    "                    #Venue\n",
    "                    venues = read_csv(path,\n",
    "                                      keep_default_na=False,\n",
    "                                      dtype={\n",
    "                                          \"id\": \"string\",\n",
    "                                          \"title\": \"string\",\n",
    "                                          \"type\": \"string\"\n",
    "                                    })\n",
    "                    venue_internal_id = {}\n",
    "                    for idx, row in venues.iterrows():\n",
    "                        local_id = \"venue-\" + str(idx)\n",
    "                        subj = URIRef(base_url + local_id)\n",
    "                        venue_internal_id[row[\"id\"]] = subj\n",
    "\n",
    "                        if row[\"type\"] == \"journal\":\n",
    "                            dsd_graph.add((subj, RDF.type, Journal))\n",
    "                        elif row[\"type\"] == \"book\":\n",
    "                            dsd_graph.add((subj, RDF.type, Book))\n",
    "                        elif row[\"type\"] == \"proceeding\":\n",
    "                            dsd_graph.add((subj, RDF.type, Proceedings))\n",
    "                            if row[\"event\"] != \"\":\n",
    "                                dsd_graph.add((subj, event, Literal(row[\"event\"])))\n",
    "\n",
    "                        dsd_graph.add((subj, title, Literal(row[\"title\"])))\n",
    "                        dsd_graph.add((subj, identifier, Literal(row[\"id\"])))\n",
    "\n",
    "                    #publications\n",
    "                    publications = read_csv(path,\n",
    "                                            keep_default_na=False,\n",
    "                                            dtype={\n",
    "                                                \"id\": \"string\",\n",
    "                                                \"title\": \"string\",\n",
    "                                                \"type\": \"string\",\n",
    "                                                \"publication_year\": \"int\",\n",
    "                                                \"publication_venue\": \"string\",\n",
    "                                                \"issue\": \"string\",\n",
    "                                                \"volume\": \"string\",\n",
    "                                                \"chapter\": \"string\",\n",
    "                                                \"venue_type\": \"string\",\n",
    "                                                \"publisher\": \"string\",\n",
    "                                                \"event\": \"string\"\n",
    "                                            })\n",
    "\n",
    "\n",
    "                    publication_internal_id = {}\n",
    "                    for idx, row in publications.iterrows():\n",
    "                        local_id = \"publication-\" + str(idx)\n",
    "\n",
    "                        subj = URIRef(base_url + local_id)\n",
    "\n",
    "                        publication_internal_id[row[\"id\"]] = subj\n",
    "\n",
    "                        dsd_graph.add((subj, doi, Literal(row[\"id\"])))\n",
    "                        dsd_graph.add((subj, title, Literal(row[\"title\"])))\n",
    "                        dsd_graph.add((subj, publicationYear, Literal(row[\"publication_year\"])))\n",
    "\n",
    "                        if row[\"type\"] == \"journal-article\":\n",
    "                            dsd_graph.add((subj, RDF.type, JournalArticle))\n",
    "\n",
    "                            if row[\"issue\"] != \"\":\n",
    "                                dsd_graph.add((subj, issue, Literal(row[\"issue\"])))\n",
    "\n",
    "                            if row[\"volume\"] != \"\":\n",
    "                                dsd_graph.add((subj, volume, Literal(row[\"volume\"])))\n",
    "\n",
    "                        elif row[\"type\"] == \"book-chapter\":\n",
    "                            dsd_graph.add((subj, RDF.type, BookChapter))\n",
    "\n",
    "                            if row[\"chapter\"] != \"\":\n",
    "                                dsd_graph.add((subj, chapterNumber, Literal(row[\"chapter\"])))\n",
    "\n",
    "                        elif row[\"type\"] == \"proceedings-paper\":\n",
    "                            dsd_graph.add((subj, RDF.type, proceedingpapers))\n",
    "\n",
    "                        ven_local_id = \"venue-\" + str(idx)\n",
    "                        ven_subj = URIRef(base_url + ven_local_id)\n",
    "\n",
    "                        dsd_graph.add((subj, publicationVenue, ven_subj))\n",
    "\n",
    "                    elif self.path.endswith('.json'):\n",
    "\n",
    "                    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "                        json_doc = json.load(f)\n",
    "\n",
    "                        authors_doi = []\n",
    "                        family_name = []\n",
    "                        given_name = []\n",
    "                        orcid = []\n",
    "\n",
    "                        authors = json_doc['authors']\n",
    "\n",
    "                        for key in authors:\n",
    "                            for item in authors[key]:\n",
    "                                authors_doi.append(key)\n",
    "                                family_name.append(item[\"family\"])\n",
    "                                given_name.append(item[\"given\"])\n",
    "                                orcid.append(item[\"orcid\"])\n",
    "\n",
    "                        # Authors dataframe:\n",
    "                        authors_df = pd.DataFrame({\n",
    "                            \"doi\": Series(authors_doi, dtype=\"string\", name=\"doi\"),\n",
    "                            \"familyName\": Series(family_name, dtype=\"string\", name=\"familyName\"),\n",
    "                            \"givenName\": Series(given_name, dtype=\"string\", name=\"givenName\"),\n",
    "                            \"orcid\": Series(orcid, dtype=\"string\", name=\"orcid\")\n",
    "                        })\n",
    "\n",
    "                        # Populating the RDF graph with information about the authors\n",
    "\n",
    "                        for idx, row in authors_df.iterrows():\n",
    "                            if authors_df.get(row[\"orcid\"], None) is None:\n",
    "\n",
    "                                local_id = \"person-\" + str(idx + idx)\n",
    "                                subj = URIRef(base_url + local_id)\n",
    "                                authors[row[\"orcid\"]] = subj\n",
    "\n",
    "                            else:\n",
    "\n",
    "                                subj = author[row[\"orcid\"]]\n",
    "\n",
    "                            dsd_graph.add((subj, RDF.type, person))\n",
    "                            dsd_graph.add((subj, doi, Literal(row[\"doi\"])))\n",
    "                            dsd_graph.add((subj, familyName, Literal(row[\"familyName\"])))\n",
    "                            dsd_graph.add((subj, givenName, Literal(row[\"givenName\"])))\n",
    "                            dsd_graph.add((subj, identifier, Literal(row[\"orcid\"])))\n",
    "\n",
    "                        references = json_doc['references']\n",
    "\n",
    "                        references_doi = []\n",
    "                        references_cites = []\n",
    "\n",
    "                        for key in references:\n",
    "                            for item in references[key]:\n",
    "                                references_doi.append(key)\n",
    "                                references_cites.append(references)\n",
    "\n",
    "                        # References dataframe:\n",
    "                        references_df = pd.DataFrame({\n",
    "                            \"references doi\": Series(references_doi, dtype=\"string\", name=\"references doi\"),\n",
    "                            \"cites\": Series(references_cites, dtype=\"string\", name=\"cites\"),\n",
    "                        })\n",
    "\n",
    "                        # Populating the RDF graph with information about the citations\n",
    "                        for idx, row in references_df.iterrows():\n",
    "                            local_id = 'reference-' + str(idx)\n",
    "\n",
    "                            subj = URIRef(base_url + local_id)\n",
    "                            dsd_graph.add((subj, citation, Literal(row['cites'])))\n",
    "\n",
    "                        venues_id = json_doc['venues_id']\n",
    "\n",
    "                        doi = []\n",
    "                        issn_isbn = []\n",
    "\n",
    "                        for key in venues_id:\n",
    "                            for item in venues_id[key]:\n",
    "                                doi.append(key)\n",
    "                                issn_isbn.append(item)\n",
    "\n",
    "                        # Venues dataframe:\n",
    "                        venues_id_df = pd.DataFrame({\n",
    "                            \"doi\": Series(doi, dtype=\"string\", name=\"doi\"),\n",
    "                            \"venues_id\": Series(issn_isbn, dtype=\"string\", name=\"issn_isbn\")\n",
    "                        })\n",
    "\n",
    "                        # Populating the RDF graph with information about the venues\n",
    "                        for idx, row in venues_id_df.iterrows():\n",
    "                            local_id = 'venue-' + str(idx)\n",
    "\n",
    "                            subj = URIRef(base_url + local_id)\n",
    "                            dsd_graph.add((subj, venue, Literal(row['venues_id'])))\n",
    "\n",
    "                        publishers = json_doc[\"publishers\"]\n",
    "\n",
    "                        publishers_crossref = []\n",
    "                        publishers_id = []\n",
    "                        publishers_name = []\n",
    "\n",
    "                        for key in publishers:\n",
    "                            for item in publishers[key]:\n",
    "                                publishers_crossref.append(key)\n",
    "                                publishers_id.append(publishers[key][\"id\"])\n",
    "                                publishers_name.append(publishers[key][\"name\"])\n",
    "\n",
    "                        # Publishers dataframe:\n",
    "                        publishers_df = pd.DataFrame({\n",
    "                            \"crossref\": Series(publishers_crossref, dtype=\"string\", name=\"crossref\"),\n",
    "                            \"publishers_id\": Series(publishers_id, dtype=\"string\", name=\"publishers_id\"),\n",
    "                            \"publishers_name\": Series(publishers_name, dtype=\"string\", name=\"publishers_name\")\n",
    "                        })\n",
    "\n",
    "                        for idx, row in publishers_df.iterrows():\n",
    "                            local_id = \"organization-\" + str(idx)\n",
    "                            subj = URIRef(base_url + local_id)\n",
    "\n",
    "                            dsd_graph.add((subj, RDF.type, Organization))\n",
    "                            dsd_graph.add((subj, name, Literal(row[\"publishers_name\"])))\n",
    "                            dsd_graph.add((subj, identifier, Literal(row[\"publishers_id\"])))\n",
    "\n",
    "                    store = SPARQLUpdateStore()\n",
    "\n",
    "                    endpoint = self.endpointUrl\n",
    "\n",
    "                    store.open((endpoint, endpoint))\n",
    "\n",
    "                    for triple in dsd_graph.triples((None, None, None)):\n",
    "                        store.add(triple)\n",
    "\n",
    "                    store.close()\n",
    "\n",
    "                else:\n",
    "                    result = False\n",
    "\n",
    "            except ValueError:\n",
    "                print(\"Oops! This doesn't seem a valid file.\")\n",
    "                result = False\n",
    "\n",
    "            return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77cbca3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Number of triples added to the graph after processing venues and publications\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(\"-- Number of triples added to the graph after processing venues and publications\")\n",
    "print(len(my_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abe4c586",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib.plugins.stores.sparqlstore import SPARQLUpdateStore\n",
    "\n",
    "store = SPARQLUpdateStore()\n",
    "\n",
    "# The URL of the SPARQL endpoint is the same URL of the Blazegraph\n",
    "# instance + '/sparql'\n",
    "endpoint = 'http://127.0.0.1:9999/blazegraph/sparql'\n",
    "\n",
    "# It opens the connection with the SPARQL endpoint instance\n",
    "store.open((endpoint, endpoint))\n",
    "\n",
    "for triple in my_graph.triples((None, None, None)):\n",
    "   store.add(triple)\n",
    "    \n",
    "# Once finished, remeber to close the connection\n",
    "store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1400bb51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
